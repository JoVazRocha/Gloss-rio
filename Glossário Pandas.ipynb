{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"green\">Glossário Pandas</font></center>\n",
    "\n",
    "# Imports Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json                        #Para poder fazer coisas com ficheiros json            \n",
    "import os                          #Ler ficheiros em pastas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linhas:\",pd.options.display.max_rows) # = x\n",
    "print(\"Colunas:\",pd.options.display.max_columns) # = y\n",
    "print(\"Tamanho colunas:\",pd.options.display.max_colwidth) # = z\n",
    "print(\"Casas decimais:\",pd.options.display.precision) # = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directórias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Chip7/Desktop/Glossário')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()\n",
    "\n",
    "# Mover o Ficheiro\n",
    "import shutil\n",
    "\n",
    "origem = filename\n",
    "destino = 'C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\Dados\\\\2.Delta\\\\Sonae\\\\Stocks\\\\Stocks2024\\\\JanAbril'\n",
    "\n",
    "shutil.move(origem, destino)\n",
    "\n",
    "# Remover um ficheiro\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Chip7\\\\Desktop\\\\Glossário'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd # print woking directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libertar Memória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del df\n",
    "gc.collect()  # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section0\"></a>\n",
    "\n",
    "# Índice\n",
    "\n",
    "1. [Criar](#section1)<br>\n",
    "2. [Ler e Escrever](#section2)<br>\n",
    "3. [Ver](#section3)<br>\n",
    "4. [Limpar e Merge](#section4)<br>\n",
    "5. [Limitar](#section5)<br>\n",
    "6. [Datetime](#section6)<br>\n",
    "7. [Organização](#section7)<br>\n",
    "8. [Widgets](#section8)<br>\n",
    "9. [Transformar](#section9)<br>\n",
    "10. [Juntar Notebooks](#section10)<br>\n",
    "11. [Markdown](#section11)  \n",
    "12. [Gráficos](#section12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"green\">1. Criar</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u>`DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Coluna1\":[100, 200], \"Coluna2\":[300,400]})\n",
    "\n",
    "#ou através de funções\n",
    "df = pd.DataFrame(np.random.rand(4,8), columns=list(\"abcdefgh\"))\n",
    "\n",
    "#ou através de dicionários\n",
    "df = pd.DataFrame(dicionario.items(), columns=[\"Coluna1\",\"Coluna2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u>`Colunas`</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Coluna_vazia_de_strings\"] = \"\"\n",
    "df[\"Coluna_vazia_de_inteiros\"] = pd.Series(dtype='int')\n",
    "df[\"Coluna_Interessante\"] = lista_interessante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"green\">2. Ler e Escrever</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u> `Tipos de ficheiros diferentes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                > - Csv - <\n",
    "\n",
    "#Ler\n",
    "df=pd.read_csv('x.csv')\n",
    "\n",
    "#Escrever\n",
    "df.to_csv('y.csv', sep=',', index=False)\n",
    "\n",
    "#Função\n",
    "def escrever_csv(dfa, nome):\n",
    "    dfa.to_csv('%s.csv' %nome, index=False)\n",
    "\n",
    "#####################################################################\n",
    "    \n",
    "                                                > - Txt - <\n",
    "\n",
    "#Ler\n",
    "df=pd.read_csv('x.txt', delimiter='\\t', dtype='float64')\n",
    "\n",
    "#Escrever\n",
    "df.to_csv('y.txt', sep='\\t', index=False)\n",
    "\n",
    "#Função\n",
    "def escrever_txt(dfa, nome):\n",
    "    dfa.to_csv('%s.txt' %nome, sep='\\t', index=False)\n",
    "\n",
    "df=pd.read_csv('C:\\\\Users\\\\joao_\\\\OneDrive\\\\Ambiente de Trabalho\\\\oi.txt', delimiter=',')\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "                                                > - Excel - <\n",
    "\n",
    "#Ler\n",
    "df=pd.read_excel('x.xlsx', sheet_name='nome')\n",
    "#Escrever\n",
    "df.to_excel('y.xlsx', index=False)\n",
    "\n",
    "#Função\n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel('%s.xlsx' %nome, index=False)\n",
    "\n",
    "#####################################################################\n",
    "    \n",
    "                                                > - Json - <\n",
    "\n",
    "#Ler\n",
    "def ler_json(directoria, nome_ficheiro):\n",
    "    with open(directoria + nome_ficheiro+'.json', 'r') as file:\n",
    "        mapa = json.load(file)\n",
    "    return mapa\n",
    "\n",
    "#Escrever\n",
    "#Função\n",
    "def escrever_json(dicionario, directoria, nome_ficheiro):\n",
    "    with open(directoria + nome_ficheiro + '.json', 'w') as file:\n",
    "        json.dump(dicionario, file)   \n",
    "    print(f\"O dicionário está escrito em {directoria}\")\n",
    "\n",
    "\n",
    "# Como foi escrito o dicionário\n",
    "\n",
    "dfVendedor=pd.read_excel(f\"C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\Dados\\\\2.{Marca}\\\\Sonae\\\\Vendedor_Loja_2024.xlsx\", sheet_name = \"Lojas Sonae\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "dicionarioVendedores = dict(zip(dfVendedor['STORE'], dfVendedor['Vendedor']))\n",
    "\n",
    "directoria ='C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\Dados\\\\2.Delta\\\\Sonae\\\\'\n",
    "\n",
    "def escrever_json(dicionario, directoria, nome_ficheiro):\n",
    "    with open(directoria + nome_ficheiro + '.json', 'w') as file:\n",
    "        json.dump(dicionario, file)   \n",
    "    print(f\"O dicionário está escrito em {directoria}\")\n",
    "\n",
    "escrever_json(dicionarioVendedores, directoria, 'Vendedor_Loja_2024')\n",
    "\n",
    "#####################################################################\n",
    "        \n",
    "                                                > - gzip - <\n",
    "\n",
    "#Ler\n",
    "pd.read_parquet('df.parquet.gzip')\n",
    "\n",
    "#Escrever\n",
    "df.to_parquet('df.parquet.gzip', compression='gzip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u> `Coisas fixes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = None          # Passar à frente o número de linhas desejado\n",
    "skipfooter = None        # Ignorar número de últimas linhas\n",
    "usecols = [1,3] ou [1:3] # Só ler determinadas colunas\n",
    "nrows = 3\n",
    "\n",
    "dtype = {'coluna':float} # Basta pôr o tipo que queremos que a coluna tenha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u> `Múltiplos ficheiros numa pasta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se quisermos ler todos os ficheiros dentro de uma pasta\n",
    "\n",
    "directoria = 'Directória_da_Pasta'\n",
    "\n",
    "ficheiros = [file for file in os.listdir(\"Directória_da_Pasta\")]\n",
    "dataframes = []\n",
    "\n",
    "# Iterar pelos ficheiros todos dentro da directória\n",
    "for file in ficheiros:\n",
    "    df = pd.read_csv(\"Directória_da_Pasta\" + file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "dfTotal = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "# Se quisermos ler ficheiros específicos dentro de uma pasta\n",
    "\n",
    "directoria = 'Directória_da_Pasta'\n",
    "\n",
    "ficheiros = [file for file in os.listdir(\"Directória_da_Pasta\")]\n",
    "dataframes = []\n",
    "\n",
    "# Iterar pelos ficheiros de interesse dentro da directória\n",
    "for filename in os.listdir(directoria):\n",
    "    if filename.startswith(\"padrão_de_início_dos_ficheiros\") and filename.endswith(\".tipo_dos_ficheiros\"):\n",
    "        \n",
    "        filepath = os.path.join(directoria, filename)\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        # Add the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "dfTotal = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "directoria = 'C:\\\\....\\\\'\n",
    "nome_repetido = 'padrão'\n",
    "tipo = 'csv'\n",
    "\n",
    "ficheiros = sorted(glob(f'{directoria}{nome_repetido}?*.{tipo}'))\n",
    "df = pd.concat((pd.read_csv(ficheiro) for ficheiro in ficheiros), ignore_index=True) # mudar aqui a função de leitura se necessário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"green\">3. Ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Acções interessantes em dataframes (por ordem de utilização minha)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()             # Ver primeiras 4 linhas de um dataframe\n",
    ".tolist()             # Depois de acções que devolvem séries, tolist() faz com que passem a ser listas\n",
    "df.columns            # Ver todas as colunas de um dataframe\n",
    "df[\"Coluna\"].unique() # Todas as opções de valores dentro de colunas\n",
    "df.info()             # Informações variadas sobre os dataframes\n",
    "df.index              # É experimentar para perceber o resto\n",
    "df.shape\n",
    "df.value_counts()\n",
    "df.count()\n",
    "df.size\n",
    "df.dtypes\n",
    "df.describe()\n",
    ".astype('Int64')      # É mil vezes melhor porque permite nans\n",
    "\n",
    "# Funções\n",
    "df.mean()\n",
    "df.std()\n",
    "df.sum()\n",
    "df.max()\n",
    "df.min()\n",
    "df.median()\n",
    "df.quantile() # de 0 até 1, é o percentil\n",
    "\n",
    "\n",
    "from summarytools import dfSummary\n",
    "dfSummary(dfNinjas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Ver por coluna e colocar condições` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma única coluna\n",
    "df['Coluna'].head()\n",
    "df.Coluna.head()\n",
    "\n",
    "# Várias colunas\n",
    "df[['Coluna1','Coluna2','Coluna3']]\n",
    "\n",
    "\n",
    "# Criar condições de visualização\n",
    "df[(df['Coluna1']>1) & (df['Coluna2']=='Sim')].head()\n",
    "# Forma mais fácil é criar uma variável com a condição\n",
    "mask = (df['Coluna1']>1) & (df['Coluna2']=='Sim')\n",
    "df[mask].head()\n",
    "\n",
    "# Outra forma é usar o .query\n",
    "df.query('Coluna1 > 1 & Coluna2 == \"Sim\" ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"green\">4. Limpar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[''])          #Eliminar colunas escolhidas\n",
    "\n",
    "#Duplicados\n",
    "df = df.groupby('A manter').apply(lambda x: x.drop_duplicates(subset=['A eliminar'], keep='first'))\n",
    "df = df.reset_index(drop=True)\n",
    "#ou\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df = df.drop(columns=[col for col in df.columns if '24' in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colunas\n",
    "df = df.rename(columns={\"original1\": \"novo1\", \"original2\": \"novo2\"})\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "#Elementos de uma coluna\n",
    "df[\"Coluna\"] = df[\"Coluna\"].replace({\"A\": 1, \"B\": \"b\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Eliminar Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com valor específico\n",
    "df.fillna(0)\n",
    "\n",
    "#Com o valor anterior ou posterior, respectivamente\n",
    "df.fillna(method=\"ffill\")\n",
    "df.fillna(method=\"bfill\")\n",
    "\n",
    "#Eliminar linhas\n",
    "df.dropna() #todas as que têm pelo menos 1 Nan\n",
    "df.dropna(how='all') #só se todos os valores da linha forem Nan\n",
    "\n",
    "#Preencher com valores de outras colunas\n",
    "df['Coluna_com_Nan'] = df['Coluna_com_Nan'].fillna(df['Primeira_Coluna']).fillna(df['Segunda_Coluna'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Substituir letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSonae['STORE'] = dfSonae['STORE'].str.replace('L', '')\n",
    "dfSonae['STORE'] = dfSonae['STORE'].astype('Int64') # Este está aqui porque geralmente é necessário logo a seguir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Alterações da letras de maiúsculas para minúsculas ou vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Coluna_de_interesse'] = df['Coluna_de_interesse'].str.title()\n",
    "df['Coluna_de_interesse'] = df['Coluna_de_interesse'].str.upper()\n",
    "df['Coluna_de_interesse'] = df['Coluna_de_interesse'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   A          B\n",
      "0  1   (10, 20)\n",
      "1  2        [c]\n",
      "2  3  [d, e, f]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1  10\n",
       "0  1  20\n",
       "1  2   c\n",
       "2  3   d\n",
       "2  3   e\n",
       "2  3   f"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'A': [1, 2, 3],\n",
    "        'B': [(10, 20), ['c'], ['d', 'e', 'f']]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Using explode() function to transform list-like columns into rows\n",
    "df.explode('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Unir bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged=pd.merge(df1, df2, how=\"inner/left/right/outter\", on = \"x\")\n",
    "\n",
    "dataframes=[\"x\",\"y\"]\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df = df.melt(id_vars=nomesResto, value_vars=nomesProd, var_name='DESC_ARTIGO', value_name='NinjaInfo')\n",
    "df_wide = df_long.pivot_table(index='Name', columns='Date', values='Value', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Somar colunas\n",
    "df['new_column'] = df[['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"green\">5. Limitar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Seleccionar determinadas linhas trendo em contra palavras chave`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O novo dataframe vai ser uma parte do dataframe total\n",
    "\n",
    "dfInteressante = df[df[\"Coluna_de_interesse\"].str.contains(\"Palavra_Escolhida\")]\n",
    "dfInteressante = df[df[\"Coluna_de_interesse\"].str.endswith(\"Palavra_Escolhida\")]\n",
    "dfInteressante = df[df[\"Coluna_de_interesse\"].str.startswith(\"Palavra_Escolhida\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Seleccionar determinadas Colunas nomes de Colunas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar lista de colunas a excluir para estabelecer que colunas manter\n",
    "Lista_Colunas_a_Manter = [x for x in Todas_Colunas if x not in Colunas_Eliminar]\n",
    "df_Colunas_Certas = df_Total[Lista_Colunas_a_Manter]\n",
    "df_Colunas_Certas = df.drop(columns=[Lista_Colunas_a_Manter])\n",
    "\n",
    "\n",
    "\n",
    "# Usar a função filter para escolher colunas que contenham palavras chave\n",
    "df[[\"DATA\"] + df.filter(like='Palavra/Expressão_Escolhida').columns.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilização básica do split\n",
    "\n",
    "frase = \"Uma, frase, muito, simples!\"\n",
    "palavras = frase.split() # Separa as palavras em strings diferentes pelo espaço\n",
    "palavras2 = frase.split(',') # Separa as palavras em strings diferentes pela vírgula\n",
    "# A seguir daria jeito fazer um strip\n",
    "\n",
    "# Criar 2 colunas a partir de uma, separando valores por um elemento constante\n",
    "df[['new_column_1', 'new_column_2']] = df['column_to_split'].str.split('-', expand=True)\n",
    "\n",
    "\n",
    "# Se quiser fazer split de um elemento apenas mete-se n = valor\n",
    "my_string = \"apple orange banana mango\"\n",
    "result = my_string.split(\" \", 1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Strip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tirar elementos do início e fim de uma string\n",
    "\n",
    "texto = \"   Hello, World!###    \"\n",
    "semEspaço = texto.strip() # Tira o espaço da esquerda e da direita\n",
    "semEspaçoCardinal = semEspaço.strip('#') # Tira os cardinais à direita (e à esquerda se houvesse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"green\">6. Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_datetime.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar para datetime\n",
    "df['DATA']= pd.to_datetime(df['DATA'], format='%d/%m/%Y'ou '%d-%m-%Y')\n",
    "\n",
    "# Limpar a data para aparecer apenas ano, mês e dia\n",
    "df['DATA'] = df['DATA'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "df['DATA'].dt.strftime('%H:%M') #apenas hora e minuto\n",
    "\n",
    "# Ver dados entre determinadas datas\n",
    "df[df[\"DATA\"].between(\"data_início\", \"data_fim\")].head()\n",
    "\n",
    "# Mudar o ano\n",
    "df.loc[df['DATA'].dt.year == 2021, 'DATA'] = df.loc[dfTeste['DATA'].dt.year == 2021, 'DATA'] + pd.offsets.DateOffset(years=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Componentes da Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ano\"] = df['Data'].dt.year\n",
    "\n",
    "df[\"Mês\"] = df['Data'].dt.month\n",
    "\n",
    "df[\"Dia\"] = df['Data'].dt.day\n",
    "\n",
    "df[\"Hora\"] = df['Data'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATA'] = df['DATA'].apply(lambda x: x.replace(day=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Aceder a dias da semana`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATA'].dt.weekday.isin([0, 4]) # dias de segunda a sexta\n",
    "df['DATA'].dt.weekday.isin([5, 6]) # dias de sábado a domingo\n",
    "        \n",
    "df_Semana = df[df['DATA'].dt.weekday.isin([0, 4])]\n",
    "df_Fds = df[df['DATA'].dt.weekday.isin([5, 6])] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Fazer coluna com dias da semana`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dia_da_Semana'] = df['DATA'].dt.day_name().map({'Monday': \"Segunda\",\n",
    "                                                    'Tuesday': \"Terça\",\n",
    "                                                    'Wednesday': \"Quarta\",\n",
    "                                                    'Thursday': \"Quinta\",\n",
    "                                                    'Friday': 'Sexta', \n",
    "                                                    'Saturday': 'Sábado', \n",
    "                                                    'Sunday': 'Domingo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Mudar datas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['DATA'].dt.day == 28, 'DATA'] = df['DATA'] - pd.Timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section7\"></a>\n",
    "# <font color=\"green\">7. Organização</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Ordenar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = [\"x\", \"y\", \"z\"])\n",
    "df.sort_values(by = ['x','y'], ascending=[False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrganizado = df.iloc[:, np.r_[:5,6:9,-1,5,-2,-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numera as colunas para ser mais fácil organizar posteriormente o DataFrame: Magia\n",
    "[f\"{index}: {column}\" for index, column in enumerate(df.columns.tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Fazer um dicionário`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = dict(zip(df['Coluna_Chave'], df['Coluna_Alvo']))\n",
    "#ou \n",
    "dicionario = df.set_index('Coluna_Chave')['Coluna_Alvo'].to_dict()\n",
    "\n",
    "# Usar o dicionário\n",
    "df[\"Novo\"] = df[\"Chave\"].map(dicionario)           # Para colunas novas\n",
    "df[\"Existente\"] = df[\"Chave\"].replace(dicionario)  # Para substituir colunas existentes (o map também dá)\n",
    "\n",
    "df['Codigo_Loja'] = df['Codigo_Loja'].fillna(df['Loja'].map(dicionarioCodigoLojas))\n",
    "\n",
    "my_dict_int = {int(key): value for key, value in my_dict_str.items()}\n",
    "\n",
    "\n",
    "#usar dicionário para renomear as colunas\n",
    "df = df.rename(columns=lambda x: dicionario.get(x, x))\n",
    "\n",
    "# Inverter dicionário\n",
    "reversed_dict = {value: key for key, values in original_dict.items() for value in values}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <u>`Arredondar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# À unidade:\n",
    "round(17.49)\n",
    "round(df['Coluna_de_Interesse'])\n",
    "\n",
    "# A determinadas casas decimais:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loc, iloc, at, iat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O loc é muito importante porque para além de permitir __`acessar`__ partes específicas de uma base, também permite __`alterar`__ os dados! <br>\n",
    "- Eu utilizo muito a forma de acessar <u>`sem loc`</u> porque me é mais natural e acho que fica melhor organizado, mas essa forma não permite alterar os dados!\n",
    "> Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condição = df.Valor >= 5  # por exemplo\n",
    "\n",
    "# Acessar\n",
    "\n",
    "df.loc[condição, 'coluna']                       # com loc\n",
    "df[condição]['coluna'] ou df[condição].coluna    # sem loc\n",
    "\n",
    "#Alterar\n",
    "\n",
    "df.loc[condição, 'coluna'] = valor_desejado      # Funciona!\n",
    "df[condição].coluna = valor_desejado             # Não funciona! :(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4], 'B': [5, 6, 7, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# loc\n",
    "df.loc[df['A'] > 2, 'B'] = 10\n",
    "\n",
    "# iloc\n",
    "df.iloc[1:3, 0] = 0\n",
    "\n",
    "# at\n",
    "df.at[0, 'A'] = 100\n",
    "\n",
    "# iat\n",
    "df.iat[2, 1] = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section8\"></a>\n",
    "# <font color=\"green\">8. Widgets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "@interact\n",
    "def filtrar_produto(produto = list(df1.DESC_ARTIGO.unique())):\n",
    "    \n",
    "    return df1[df1.DESC_ARTIGO == produto].head() # Alterável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def filtrar_loja(loja = list(df1.Loja.unique())):\n",
    "    \n",
    "    return df1[df1.Loja == loja].head() # Alterável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Há notificações!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deu? :O\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"5cde7557-44fa-4e06-a847-a266a67d6117\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"5cde7557-44fa-4e06-a847-a266a67d6117\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "\n",
    "import time\n",
    "import random \n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "print('Deu? :O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section9\"></a>\n",
    "# <font color=\"green\">9. Transformar</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Column_A'] = pd.to_numeric(df['Column_A'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is called 'df'\n",
    "column_values = df['DESC_ARTIGO'].values.tolist()\n",
    "\n",
    "# Or, if you want to create a new pandas Series instead of a list:\n",
    "column_series = pd.Series(df['DESC_ARTIGO'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementos_não_presentes_em_ambos = set(df1_columns) ^ set(df2_columns)\n",
    "\n",
    "união_de_elementos = set(df1_columns) | set(df2_columns)\n",
    "\n",
    "intersecção = set(df1_columns) & set(df2_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section10\"></a>\n",
    "# <font color=\"green\">10. Mergir Notebooks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nbformat\n",
    "\n",
    "notebook_A = nbformat.read(\"C:\\\\Users\\\\joao_\\\\OneDrive\\Ambiente de Trabalho\\\\B&N Código\\\\Lactogal\\\\cPadrão\\\\1LJunho_DataCleaning.ipynb\", nbformat.NO_CONVERT)\n",
    "notebook_B = nbformat.read(\"C:\\\\Users\\\\joao_\\\\OneDrive\\Ambiente de Trabalho\\\\B&N Código\\\\Lactogal\\\\cPadrão\\\\2LJunho_Wide_Wrangling.ipynb\", nbformat.NO_CONVERT)\n",
    "notebook_C = nbformat.read(\"C:\\\\Users\\\\joao_\\\\OneDrive\\Ambiente de Trabalho\\\\B&N Código\\\\Lactogal\\\\cPadrão\\\\5_GráficosR.ipynb\", nbformat.NO_CONVERT)\n",
    "\n",
    "\n",
    "\n",
    "notebook_A.cells.extend(notebook_B.cells)\n",
    "notebook_A.cells.extend(notebook_C.cells)\n",
    "\n",
    "\n",
    "nbformat.write(notebook_A, \"C:\\\\Users\\\\joao_\\\\OneDrive\\Ambiente de Trabalho\\\\B&N Código\\\\Lactogal\\\\cPadrão\\\\Lacto_Completo.ipynb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "# <font color=\"green\">11. Markdown</font>\n",
    "> Estrutura dos programas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style = 'color:#daa520'>**Imports**</span>\n",
    "\n",
    "\n",
    "\n",
    "# <span style='color:#006633'>Índice</span>\n",
    "1. [xxx](#section0)  \n",
    "2. [yyy](#section1)  \n",
    "3. [zzz](#section2) \n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "\n",
    "\n",
    "\n",
    "# <span style='color:#015EC5'> Ninjas </span>\n",
    "\n",
    "\n",
    "\n",
    "# <span style='color:#015EC5'> Stocks Sellouts </span>\n",
    "\n",
    "\n",
    "## <span style = 'color:#330066'> Colunas Novas </span>\n",
    "\n",
    "\n",
    "> Espaço_Para_Coisas_Como_colunas_novas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~Span~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style='color:blue; font-family: Times New Roman; background-color: yellow'>Span tem imensas coisas fixes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "# <font color=\"green\">12. Gráficos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melhorar qualidade do gráfico quando feito o zoom\n",
    "> Transforma o output de uma imagem para passar a renderizar como um vector: scalable vector graphic (SVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "# Ou\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gráfico a correr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bar_chart_race as bcr\n",
    "\n",
    "df = pd.DataFrame({\"x\":[2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010], \n",
    "                   \"y\":[0,2,4,6,10,15,19,20,23,25,28], \n",
    "                   \"z\":[0,3,3,7,9,16,22,25,27,30,33], \n",
    "                   \"w\":[0,2,3,5,8,13,19,28,33,35,40]})\n",
    "\n",
    "# bcr.bar_chart_race(df=df,\n",
    "#                   title = 'Como fazer um gráfico de barras que correm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Índice](#section0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section13\"></a>\n",
    "# <font color=\"green\">13. E-mails</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email enviado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "GMAIL_CREDENTIALS_PATH = os.environ.get(\"GMAIL_CREDENTIALS_PATH\", 'C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\credenciaisEnvio.yml') \n",
    "\n",
    "\n",
    "\n",
    "with open(GMAIL_CREDENTIALS_PATH) as f:\n",
    "    content = f.read()\n",
    "credenciaisEnvio = yaml.load(content, Loader = yaml.FullLoader)\n",
    "\n",
    "# Atribuir as credenciais a variáveis\n",
    "user, password = credenciaisEnvio['user'], credenciaisEnvio['password']\n",
    "\n",
    "destino = 'joao@brandsandninjas.com'\n",
    "\n",
    "\n",
    "#df = 'dataframe'\n",
    "# Converter para html para entrar no mail\n",
    "#df_html = df.to_html(index=False)\n",
    "\n",
    "\n",
    "# Create the MIME object for the email\n",
    "message = MIMEMultipart()\n",
    "message[\"From\"] = user\n",
    "message[\"To\"] = destino\n",
    "message[\"Subject\"] = \"Produtos que precisam de atenção\"\n",
    "\n",
    "# Add the email body\n",
    "\n",
    "#{df_html} por isto para adicionar o dataframe ao corpo\n",
    "body = f\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "message.attach(MIMEText(body, \"html\"))\n",
    "\n",
    "# Connect to the SMTP server (in this case, Gmail's SMTP server)\n",
    "with smtplib.SMTP(\"smtp.gmail.com\", 587) as server:\n",
    "    # Start TLS encryption\n",
    "    server.starttls()\n",
    "\n",
    "    # Log in to the email account\n",
    "    server.login(user, password)\n",
    "\n",
    "    # Send the email\n",
    "    server.sendmail(user, destino, message.as_string())\n",
    "\n",
    "print(f\"Email enviado com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **função separar fins de semana**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para definir qual fim de semana queremos pedir\n",
    "def fds(nome, df, numero):\n",
    "    a = int(numero)\n",
    "    b = 3*(a-1)\n",
    "    nome=df[b:b+3].copy()\n",
    "    return nome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Extrair apenas os fins de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFds = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])].copy()         #Sexta, Sábado e Domingo\n",
    "#dfSemana = dfJuntos[dfJuntos['DATA'].dt.weekday.isin([0,1,2,3])]    #Segunda a Quinta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Fins de semana homólogos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dias em causa (1 fds depois da páscoa)\n",
    "dfFdsPiloto=dfFds.loc[(dfFds['DATA'] >= '2022-04-22') & (dfFds['DATA'] <= '2022-05-15')].copy()\n",
    "\n",
    "#Organizar para dar para ler mais facilmente\n",
    "dfFdsPiloto=dfFdsPiloto.sort_values(by=[\"STORE\", \"DESC_ARTIGO\",\"DATA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Colunas para a **semana** e o **dia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar para fazer alterações mantendo o original\n",
    "dfFdsFinal = dfFdsPiloto.copy()\n",
    "\n",
    "#Semana\n",
    "dfFdsFinal['Semana'] = dfFdsFinal['DATA'].dt.isocalendar().week\n",
    "dfFdsFinal['Semana'] = dfFdsFinal.groupby('Semana').ngroup() + 1\n",
    "\n",
    "#Dia\n",
    "nome_dia = dfFdsFinal['DATA'].dt.day_name().map({'Friday': 'Sexta', 'Saturday': 'Sábado', 'Sunday': 'Domingo'})\n",
    "dfFdsFinal['Dia'] = nome_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://bit.ly/drinksbycountry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>beer_servings</th>\n",
       "      <th>spirit_servings</th>\n",
       "      <th>wine_servings</th>\n",
       "      <th>total_litres_of_pure_alcohol</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>89</td>\n",
       "      <td>132</td>\n",
       "      <td>54</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>245</td>\n",
       "      <td>138</td>\n",
       "      <td>312</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>217</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  beer_servings  spirit_servings  wine_servings  \\\n",
       "0  Afghanistan              0                0              0   \n",
       "1      Albania             89              132             54   \n",
       "2      Algeria             25                0             14   \n",
       "3      Andorra            245              138            312   \n",
       "4       Angola            217               57             45   \n",
       "\n",
       "   total_litres_of_pure_alcohol continent  \n",
       "0                           0.0      Asia  \n",
       "1                           4.9    Europe  \n",
       "2                           0.7    Africa  \n",
       "3                          12.4    Europe  \n",
       "4                           5.9    Africa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6540\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6534\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6538\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6539\u001b[0m ):\n\u001b[1;32m-> 6540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12417\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12412\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12415\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12416\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12419\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12374\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12372\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12375\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12376\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6448\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6447\u001b[0m     )\n\u001b[1;32m-> 6448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string 'AlgeriaAngolaBeninBotswanaBurkina FasoBurundiCote d'IvoireCabo VerdeCameroonCentral African RepublicChadComorosCongoDR CongoDjiboutiEgyptEquatorial GuineaEritreaEthiopiaGabonGambiaGhanaGuineaGuinea-BissauKenyaLesothoLiberiaLibyaMadagascarMalawiMaliMauritaniaMauritiusMoroccoMozambiqueNamibiaNigerNigeriaRwandaSao Tome & PrincipeSenegalSeychellesSierra LeoneSomaliaSouth AfricaSudanSwazilandTogoTunisiaUgandaTanzaniaZambiaZimbabwe' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "df.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
